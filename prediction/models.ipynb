{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Математична модель прогнозування часових проміжків\n",
    "\n",
    "Для дослідження часових рядів головними чинниками є опис та моделювання їх структури. Побудована модель може використовуватися для екстраполяції або прогнозування часового ряду, що є ключовим аспектом у визначенні результатів перегонів чемпіонату Формули 1. У цій курсовій роботі були використані різні математичні моделі для прогнозування результатів перегонів, а саме k-найближчих сусідів (KNN), випадковий ліс (Random Forest), логістична регресія (Logistic Regression) та метод опорних векторів (SVM).\n",
    "\n",
    "#### Модель k-найближчих сусідів (KNN)\n",
    "\n",
    "Модель k-найближчих сусідів (KNN) базується на знаходженні k найближчих зразків у просторі ознак та класифікації на основі їхніх значень. Формально, для нової точки $ x $, прогнозується значення $ y $ на основі середнього (або найчастішого) значення серед найближчих сусідів:\n",
    "\n",
    "$$ \\hat{y} = \\frac{1}{k} \\sum_{i=1}^{k} y_{(i)} $$\n",
    "\n",
    "де $ y_{(i)} $ – значення найближчих сусідів. Вибір параметру $ k $ здійснюється на основі крос-валідації, щоб забезпечити баланс між обчислювальною складністю та точністю моделі.\n",
    "\n",
    "#### Випадковий ліс (Random Forest)\n",
    "\n",
    "Випадковий ліс складається з множини дерев рішень, де кожне дерево рішень створюється на основі випадкової вибірки з навчальної множини. Прогноз для нового зразка робиться шляхом усереднення (для регресії) або голосування (для класифікації) результатів окремих дерев:\n",
    "\n",
    "$$ \\hat{y} = \\frac{1}{B} \\sum_{b=1}^{B} T_b(x) $$\n",
    "\n",
    "де $ B $ – кількість дерев у лісі, а $ T_b(x) $ – прогноз окремого дерева.\n",
    "\n",
    "#### Логістична регресія (Logistic Regression)\n",
    "\n",
    "Логістична регресія використовується для прогнозування ймовірності належності до певного класу. Модель має вигляд:\n",
    "\n",
    "$$ P(y=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_p X_p)}} $$\n",
    "\n",
    "де $ \\beta_0, \\beta_1, \\ldots, \\beta_p $ – параметри моделі, що оцінюються методом максимальної правдоподібності. Вона добре підходить для бінарних класифікаційних задач і надає інтерпретовані коефіцієнти.\n",
    "\n",
    "#### Метод опорних векторів (SVM)\n",
    "\n",
    "Метод опорних векторів (SVM) шукає гіперплощину, що максимально розділяє класи в багатовимірному просторі. Функція рішення має вигляд:\n",
    "\n",
    "$$ f(x) = \\sum_{i=1}^{N} \\alpha_i y_i K(x_i, x) + b $$\n",
    "\n",
    "де $ \\alpha_i $ – вагові коефіцієнти, $ y_i $ – класові мітки, $ K(x_i, x) $ – ядро (наприклад, лінійне, поліноміальне, RBF), а $ b $ – зміщення. SVM ефективний для задач з високою розмірністю та нелінійними розділеннями.\n",
    "\n",
    "Обрані моделі для прогнозування результатів перегонів чемпіонату Формули 1 дають змогу аналізувати складні залежності та взаємодії між різними змінними. Подальший аналіз даних на кожній з моделей та порівняння їх ефективності буде описано в наступних підрозділах.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
